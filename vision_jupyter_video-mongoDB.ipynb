{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT VISION - Rediscovering Mobility For Blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "from  matplotlib import pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cam Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stereo_coefficients(path):\n",
    "    \"\"\" \n",
    "    Loads stereo matrix coefficients. \n",
    "    \"\"\"\n",
    "    # FILE_STORAGE_READ\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "\n",
    "    # note we also have to specify the type to retrieve other wise we only get a\n",
    "    # FileNode object back instead of a matrix\n",
    "    K1 = cv_file.getNode(\"K1\").mat()\n",
    "    D1 = cv_file.getNode(\"D1\").mat()\n",
    "    K2 = cv_file.getNode(\"K2\").mat()\n",
    "    D2 = cv_file.getNode(\"D2\").mat()\n",
    "    R = cv_file.getNode(\"R\").mat()\n",
    "    T = cv_file.getNode(\"T\").mat()\n",
    "    E = cv_file.getNode(\"E\").mat()\n",
    "    F = cv_file.getNode(\"F\").mat()\n",
    "    R1 = cv_file.getNode(\"R1\").mat()\n",
    "    R2 = cv_file.getNode(\"R2\").mat()\n",
    "    P1 = cv_file.getNode(\"P1\").mat()\n",
    "    P2 = cv_file.getNode(\"P2\").mat()\n",
    "    Q = cv_file.getNode(\"Q\").mat()\n",
    "\n",
    "    cv_file.release()\n",
    "    return [K1, D1, K2, D2, R, T, E, F, R1, R2, P1, P2, Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1, D1, K2, D2, R, T, E, F, R1, R2, P1, P2, Q = load_stereo_coefficients(\n",
    "    \"calibration/calibration_file.txt\"\n",
    ")  # Get cams params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding the distance of each pixel of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_map(imgL, imgR):\n",
    "    \"\"\" \n",
    "    Depth map calculation. Works with SGBM and WLS. \n",
    "    Need rectified images, returns depth map ( left to right disparity ) \n",
    "    \"\"\"\n",
    "    # SGBM Parameters\n",
    "    window_size = 7  \n",
    "    # wsize \n",
    "    # default 3; 5; \n",
    "    # 7 for SGBM reduced size image; \n",
    "    # 15 for SGBM full size image (1300px and above); \n",
    "    # 5 Works nicely\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(\n",
    "        minDisparity=1,\n",
    "        numDisparities= 5 * 16,  # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "        blockSize= window_size,\n",
    "        P1=8 * 3 * window_size,\n",
    "        P2= 32 * 3 * window_size,\n",
    "        disp12MaxDiff=12,\n",
    "        uniquenessRatio=10,\n",
    "        speckleWindowSize=50,\n",
    "        speckleRange=32,\n",
    "        preFilterCap=63,\n",
    "        mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY,\n",
    "    )\n",
    "    # wls_filter.setSigmaColor(sigma)\n",
    "    displ = left_matcher.compute(imgL, imgR).astype(np.float32) / 16\n",
    "    return displ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = 'yolo'\n",
    "#extracting network from yolov3.weights \n",
    "net = cv2.dnn.readNet(f'{path_dir}/yolov3.weights' , f'{path_dir}/yolov3.cfg')\n",
    "\n",
    "#extracting the name of objects\n",
    "with open(f'{path_dir}/coco.names','r' ) as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capL = cv2.VideoCapture(1)\n",
    "capR = cv2.VideoCapture(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://Nishant:testgudipaty@testcluster-shard-00-00.p19xk.mongodb.net:27017,testcluster-shard-00-01.p19xk.mongodb.net:27017,testcluster-shard-00-02.p19xk.mongodb.net:27017/myFirstDatabase?ssl=true&replicaSet=atlas-w9nbtk-shard-0&authSource=admin&retryWrites=true&w=majority\")\n",
    "db = client[\"vision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #rightFrame = cv2.imread(\"images/right.jpeg\")\n",
    "    #leftFrame = cv2.imread(\"images/left.jpeg\", cv2.IMREAD_COLOR)\n",
    "    if not (capL.grab() and capR.grab()):\n",
    "        print(\"No more frames\")\n",
    "        break\n",
    "\n",
    "    _, leftFrame = capL.retrieve()\n",
    "    _, rightFrame = capR.retrieve()\n",
    "\n",
    "    cv2.imshow(\"capL\", leftFrame)\n",
    "    cv2.imshow(\"capR\", rightFrame)\n",
    "\n",
    "    height, width, channel = leftFrame.shape  # We will use the shape for remap\n",
    "\n",
    "    print(\"Images from camera: \")\n",
    "    #plotting\n",
    "    f, ax = plt.subplots(1,2, figsize=(12, 3))\n",
    "    ax[0].imshow(cv2.cvtColor(leftFrame, cv2.COLOR_BGR2RGB))\n",
    "    ax[1].imshow(cv2.cvtColor(rightFrame, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    Undistortion and Rectification part! Undistorts and Rectifies the images using the Calibration codes\n",
    "    \"\"\"\n",
    "    leftMapX, leftMapY = cv2.initUndistortRectifyMap(\n",
    "        K1, D1, R1, P1, (width, height), cv2.CV_32FC1\n",
    "    )\n",
    "    left_rectified = cv2.remap(\n",
    "        leftFrame, leftMapX, leftMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT\n",
    "    )\n",
    "    rightMapX, rightMapY = cv2.initUndistortRectifyMap(\n",
    "        K2, D2, R2, P2, (width, height), cv2.CV_32FC1\n",
    "    )\n",
    "    right_rectified = cv2.remap(\n",
    "        rightFrame, rightMapX, rightMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT\n",
    "    )\n",
    "\n",
    "    print(\"After rectification: \")\n",
    "    #plotting\n",
    "    f, ax = plt.subplots(1,2, figsize=(12, 3))\n",
    "    ax[0].imshow(cv2.cvtColor(left_rectified, cv2.COLOR_BGR2RGB))\n",
    "    ax[1].imshow(cv2.cvtColor(right_rectified, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    disp_matrix = depth_map(gray_left, gray_right)\n",
    "    \"\"\"\n",
    "    #We need grayscale for disparity map.\n",
    "    gray_left = cv2.cvtColor(leftFrame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(rightFrame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    disp_matrix = depth_map(rightFrame, leftFrame)  # Get the disparity map\n",
    "    #print(disp_matrix)\n",
    "\n",
    "    print(\"Depth map:\")\n",
    "    plt.figure(figsize=(15, 4.5))\n",
    "    plt.imshow(cv2.cvtColor(disp_matrix, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    distance_matrix = (base offset x focal length)/disp_matrix\n",
    "    \"\"\"\n",
    "    distance_matrix = []\n",
    "    base =  0.07 # 1 / Q[3, 2] base offset (distance between the two cameras)\n",
    "    focal = Q[2, 3] # Focal Length of the cameras\n",
    "\n",
    "    infi = 10e15;count =0\n",
    "    for i in range(disp_matrix.shape[0]):\n",
    "        for j in range(disp_matrix.shape[1]): \n",
    "            if disp_matrix[i][j] == 0:\n",
    "                disp_matrix[i][j] = (1/infi)\n",
    "\n",
    "    distance_matrix = (base*focal)/disp_matrix\n",
    "    print(distance_matrix)\n",
    "\n",
    "    \"\"\"\n",
    "    VIDEO CAPTURE\n",
    "    \"\"\"\n",
    "    #cap = cv.VideoCapture(0)\n",
    "    #BGR image loaded\n",
    "    img = rightFrame\n",
    "    img_copy = rightFrame\n",
    "\n",
    "    #while True:\n",
    "    #_,img = cap.read()\n",
    "    #height ,width and layersof the image\n",
    "    height,width,l = img.shape \n",
    "\n",
    "    #resize to RGB (0-1 scale) 416 image for yolo\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255 , (416,416),(0,0,0) , swapRB= True , crop = False)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Model Input\n",
    "    \"\"\"\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames() #finiding the unconnected layers\n",
    "    layerOutputs = net.forward(output_layers_names) #returns an array of output layers\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Detecting the rectangle with max confidence\n",
    "    \"\"\"\n",
    "    boxes = [] #stores the top left corner index of the box and the h and w \n",
    "    confidences = [] #storesthe max conf of the box \n",
    "    class_ids = [] #stores the index of max conf \n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:] #first 5 are the dimensions of box and if object is present or not \n",
    "            class_id = np.argmax(scores)\n",
    "            conf = scores[class_id]\n",
    "            # Setting confidence threshold = 0.1\n",
    "            if conf > 0.1:\n",
    "                cx = int(detection[0]*width) #center x of the box\n",
    "                cy = int(detection[1]*height) #center y of the box\n",
    "                w= int(detection[2]*width)\n",
    "                h=int(detection[3]*height)\n",
    "\n",
    "                bx = int(cx-w/2) #left corner x\n",
    "                by = int(cy-h/2) #left corner y\n",
    "\n",
    "                boxes.append([bx,by,w,h])\n",
    "                confidences.append((float(conf)))\n",
    "                class_ids.append(class_id) \n",
    "\n",
    "    #Non-max supression\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes , confidences ,0.3 ,0.4)\n",
    "    print(indexes)\n",
    "\n",
    "    #font and different colours\n",
    "    font = cv2.FONT_HERSHEY_PLAIN \n",
    "    colors = np.random.uniform(0,255 , size=(len(boxes),3))\n",
    "    \n",
    "    centre = []\n",
    "    distance = []\n",
    "    labels = []\n",
    "    \n",
    "    #Drawing Rectangles\n",
    "    for i in indexes.flatten():\n",
    "        top_leftX,top_leftY,width,height = boxes[i] \n",
    "        label = str(classes[class_ids[i]]) #name of the object\n",
    "        confidence = str(round(confidences[i],2)) #confidence of the object\n",
    "        #print (i , \" : \" , label , \" : \" , confidence )\n",
    "        print (\"detected object: \", label)\n",
    "        print (\"confidence: \" , confidence)\n",
    "        print( \"x-coordinate: \" , top_leftX , \"\\t\" , \"y-coordinate:indexes\" , top_leftY)\n",
    "        print(\"width: \" , width , \"\\t\" , \"height: \" , height)\n",
    "        sum =0; count=1; flag=1\n",
    "        \n",
    "        for x in range(top_leftY,min(top_leftY+height,480)):\n",
    "            for y in range(top_leftX,min(top_leftX+width,640)):\n",
    "                if distance_matrix[x][y]<15:\n",
    "                    sum += distance_matrix[x][y]\n",
    "                    if (flag):\n",
    "                        flag=0\n",
    "                    else:\n",
    "                        count+=1\n",
    "        dist = sum/count\n",
    "        print(f\"{label} distance: {round(dist,2)}m\\n\")\n",
    "        if label == \"person\":\n",
    "            distance.append(round(dist,2))\n",
    "            centre.append([top_leftX + (width/2), top_leftY + (height/2)])\n",
    "        color = colors[i] \n",
    "        cv2.rectangle(img_copy , (top_leftX,top_leftY) , (top_leftX+width , top_leftY+height) , color , 2)\n",
    "        cv2.putText(img_copy,label+\" - \" + f\"{round(dist,2)}m\", (top_leftX , top_leftY+20) , font , 1 ,(255,255,255),2)\n",
    "    \n",
    "    led_left = 0\n",
    "    led_right = 0\n",
    "\n",
    "    mid = 640/2\n",
    "    if(len(distance) == 0):\n",
    "        led_left = 0; left_right = 0\n",
    "    else: \n",
    "        i = distance.index(min(distance))\n",
    "    #     for i in range(len(distance)):\n",
    "    #         if centre[i][0] <= mid and distance[i] <= 4:\n",
    "    #             led_left = 1;\n",
    "    #         elif centre[i][0] > mid and distance[i] <= 4:\n",
    "    #             led_right = 1\n",
    "        if centre[i][0] <= mid:\n",
    "            led_left = 1; left_right = 0\n",
    "        elif centre[i][0] > mid:\n",
    "            led_left = 0;left_right = 1\n",
    "    \n",
    "    result = db[\"motor_data\"].delete_many({})\n",
    "    document = {\n",
    "        \"led_left\": led_left,\n",
    "        \"led_right\": led_right\n",
    "    }\n",
    "    result = db[\"motor_data\"].insert_one(document)\n",
    "    \n",
    "    # cv2.imshow(img_copy) \n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
